{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "466c7080",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-12T12:53:41.524597Z",
     "iopub.status.busy": "2024-09-12T12:53:41.523933Z",
     "iopub.status.idle": "2024-09-12T12:53:43.611830Z",
     "shell.execute_reply": "2024-09-12T12:53:43.611060Z"
    },
    "papermill": {
     "duration": 2.095197,
     "end_time": "2024-09-12T12:53:43.614045",
     "exception": false,
     "start_time": "2024-09-12T12:53:41.518848",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Ariel Data Challenge 2024: Exoplanet Spectrum Analysis Pipeline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import signal\n",
    "from scipy.ndimage import gaussian_filter1d\n",
    "from scipy.optimize import minimize\n",
    "from scipy.signal import savgol_filter\n",
    "from scipy.interpolate import interp1d\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import gc\n",
    "import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f399f4fc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-12T12:53:43.622810Z",
     "iopub.status.busy": "2024-09-12T12:53:43.622367Z",
     "iopub.status.idle": "2024-09-12T12:53:43.628439Z",
     "shell.execute_reply": "2024-09-12T12:53:43.627486Z"
    },
    "papermill": {
     "duration": 0.012622,
     "end_time": "2024-09-12T12:53:43.630441",
     "exception": false,
     "start_time": "2024-09-12T12:53:43.617819",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 1. Data Loading Functions\n",
    "\n",
    "def load_planet_data(planet_id, data_path):\n",
    "    airs_signal = pd.read_parquet(f\"{data_path}/train/{planet_id}/AIRS-CH0_signal.parquet\")\n",
    "    fgs1_signal = pd.read_parquet(f\"{data_path}/train/{planet_id}/FGS1_signal.parquet\")\n",
    "    \n",
    "    calibration_files = {\n",
    "        'dark': pd.read_parquet(f\"{data_path}/train/{planet_id}/AIRS-CH0_calibration/dark.parquet\"),\n",
    "        'flat': pd.read_parquet(f\"{data_path}/train/{planet_id}/AIRS-CH0_calibration/flat.parquet\"),\n",
    "        'dead': pd.read_parquet(f\"{data_path}/train/{planet_id}/AIRS-CH0_calibration/dead.parquet\"),\n",
    "        'linear_corr': pd.read_parquet(f\"{data_path}/train/{planet_id}/AIRS-CH0_calibration/linear_corr.parquet\")\n",
    "    }\n",
    "    \n",
    "    return airs_signal, fgs1_signal, calibration_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "805ec832",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-12T12:53:43.638622Z",
     "iopub.status.busy": "2024-09-12T12:53:43.638265Z",
     "iopub.status.idle": "2024-09-12T12:53:43.650943Z",
     "shell.execute_reply": "2024-09-12T12:53:43.650164Z"
    },
    "papermill": {
     "duration": 0.018945,
     "end_time": "2024-09-12T12:53:43.652764",
     "exception": false,
     "start_time": "2024-09-12T12:53:43.633819",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 2. Data Preprocessing Functions\n",
    "\n",
    "def reshape_and_calibrate(airs_signal, calibration_files):\n",
    "    airs_data = airs_signal.values.reshape(-1, 32, 356)\n",
    "    airs_data = (airs_data - calibration_files['dark'].values) / calibration_files['flat'].values\n",
    "    return airs_data\n",
    "\n",
    "def extract_spectral_data(airs_data):\n",
    "    return np.mean(airs_data, axis=1)\n",
    "\n",
    "def measure_centroid(image):\n",
    "    y, x = np.indices(image.shape)\n",
    "    total = image.sum()\n",
    "    x_center = (x * image).sum() / total\n",
    "    y_center = (y * image).sum() / total\n",
    "    return x_center, y_center\n",
    "\n",
    "def correct_jitter(airs_data, fgs1_data, airs_time, fgs1_time):\n",
    "    # Ensure FGS1 data covers the full AIRS-CH0 time range\n",
    "    fgs1_start = max(fgs1_time.min(), airs_time.min())\n",
    "    fgs1_end = min(fgs1_time.max(), airs_time.max())\n",
    "    mask = (fgs1_time >= fgs1_start) & (fgs1_time <= fgs1_end)\n",
    "    fgs1_time = fgs1_time[mask]\n",
    "    fgs1_data = fgs1_data[mask]\n",
    "\n",
    "    # Interpolate FGS1 centroid positions to AIRS-CH0 timestamps\n",
    "    interp_x = interp1d(fgs1_time, fgs1_data[:, 0], kind='cubic', fill_value='extrapolate')\n",
    "    interp_y = interp1d(fgs1_time, fgs1_data[:, 1], kind='cubic', fill_value='extrapolate')\n",
    "    \n",
    "    x_pos = interp_x(airs_time)\n",
    "    y_pos = interp_y(airs_time)\n",
    "\n",
    "    # Smooth the centroid positions to reduce noise\n",
    "    x_smooth = savgol_filter(x_pos, window_length=51, polyorder=3)\n",
    "    y_smooth = savgol_filter(y_pos, window_length=51, polyorder=3)\n",
    "\n",
    "    # Calculate pixel shifts\n",
    "    x_shift = x_smooth - np.median(x_smooth)\n",
    "    y_shift = y_smooth - np.median(y_smooth)\n",
    "\n",
    "    # Correct AIRS-CH0 data for jitter\n",
    "    corrected_data = np.zeros_like(airs_data)\n",
    "    for i in range(airs_data.shape[1]):\n",
    "        # Create a 2D interpolation function for each wavelength\n",
    "        interp_func = interp1d(airs_time, airs_data[:, i], kind='cubic', fill_value='extrapolate')\n",
    "        \n",
    "        # Apply correction\n",
    "        corrected_time = airs_time - x_shift * 0.1 - y_shift * 0.1  # Adjust scaling factors as needed\n",
    "        corrected_data[:, i] = interp_func(corrected_time)\n",
    "\n",
    "    return corrected_data\n",
    "\n",
    "def normalize_data(data):\n",
    "    mean = np.mean(data, axis=0)\n",
    "    std = np.std(data, axis=0)\n",
    "    return (data - mean) / (std + 1e-10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2f2439a4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-12T12:53:43.660809Z",
     "iopub.status.busy": "2024-09-12T12:53:43.660525Z",
     "iopub.status.idle": "2024-09-12T12:53:43.673829Z",
     "shell.execute_reply": "2024-09-12T12:53:43.673161Z"
    },
    "papermill": {
     "duration": 0.019553,
     "end_time": "2024-09-12T12:53:43.675705",
     "exception": false,
     "start_time": "2024-09-12T12:53:43.656152",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 3. Model Building Functions\n",
    "\n",
    "def simple_transit_model(params, time):\n",
    "    t0, per, depth, duration = params\n",
    "    phase = (time - t0 + 0.5*per) % per - 0.5*per\n",
    "    transit = np.abs(phase) < 0.5*duration\n",
    "    return 1 - depth * transit\n",
    "\n",
    "def fit_transit_model(flux, time):\n",
    "    def residuals(params):\n",
    "        return np.sum((flux - simple_transit_model(params, time))**2)\n",
    "    \n",
    "    initial_guess = [np.median(time), 0.1 * (time[-1] - time[0]), 0.01, 0.1 * (time[-1] - time[0])]\n",
    "    bounds = ((0, len(time)), (0, len(time)), (0, 0.1), (0, len(time)/2))\n",
    "    result = minimize(residuals, initial_guess, bounds=bounds, method='L-BFGS-B')\n",
    "    return result.x\n",
    "\n",
    "def process_planet(planet_id, data_path, axis_info):\n",
    "    # Load data\n",
    "    airs_signal, fgs1_signal, calibration_files = load_planet_data(planet_id, data_path)\n",
    "    \n",
    "    # Preprocess data\n",
    "    airs_data = reshape_and_calibrate(airs_signal, calibration_files)\n",
    "    spectral_data = extract_spectral_data(airs_data)\n",
    "    \n",
    "    # Time arrays\n",
    "    airs_time_step = axis_info['AIRS-CH0-axis0-h'].iloc[1] - axis_info['AIRS-CH0-axis0-h'].iloc[0]\n",
    "    time = np.arange(len(spectral_data)) * airs_time_step\n",
    "    \n",
    "    fgs1_data = fgs1_signal.values.reshape(-1, 32, 32)\n",
    "    fgs1_centroids = np.array([measure_centroid(frame) for frame in fgs1_data])\n",
    "    fgs1_time_step = axis_info['FGS1-axis0-h'].iloc[1] - axis_info['FGS1-axis0-h'].iloc[0]\n",
    "    fgs1_time = np.arange(len(fgs1_data)) * fgs1_time_step\n",
    "    \n",
    "    # Jitter correction\n",
    "    corrected_spectral_data = correct_jitter(spectral_data, fgs1_centroids, time, fgs1_time)\n",
    "    \n",
    "    # Fit transit model for each wavelength\n",
    "    transit_params = np.array([fit_transit_model(corrected_spectral_data[:, i], time) \n",
    "                               for i in range(corrected_spectral_data.shape[1])])\n",
    "    \n",
    "    # Extract spectrum and estimate uncertainties\n",
    "    spectrum = np.mean(corrected_spectral_data, axis=0)\n",
    "    uncertainties = np.std(corrected_spectral_data, axis=0) / np.sqrt(len(corrected_spectral_data))\n",
    "    \n",
    "    return {\n",
    "        'wavelengths': pd.read_csv(f\"{data_path}/wavelengths.csv\").iloc[0].values,\n",
    "        'spectrum': spectrum,\n",
    "        'uncertainties': uncertainties,\n",
    "        'transit_params': transit_params\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "db40b002",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-12T12:53:43.683913Z",
     "iopub.status.busy": "2024-09-12T12:53:43.683639Z",
     "iopub.status.idle": "2024-09-12T12:53:43.689278Z",
     "shell.execute_reply": "2024-09-12T12:53:43.688390Z"
    },
    "papermill": {
     "duration": 0.01173,
     "end_time": "2024-09-12T12:53:43.691140",
     "exception": false,
     "start_time": "2024-09-12T12:53:43.679410",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 4. Main Processing Loop\n",
    "def process_all_planets(data_path, train_adc_info, axis_info):\n",
    "    all_results = {}\n",
    "    total_planets = len(train_adc_info.index)\n",
    "    \n",
    "    for i, planet_id in enumerate(tqdm(train_adc_info.index, desc=\"Processing planets\")):\n",
    "        results = process_planet(str(planet_id), data_path, axis_info)\n",
    "        if results is not None:\n",
    "            all_results[planet_id] = results\n",
    "        \n",
    "        # Optional: Print progress every 10%\n",
    "        if (i + 1) % (total_planets // 10) == 0:\n",
    "            print(f\"Processed {i + 1}/{total_planets} planets\")\n",
    "    \n",
    "    return all_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d75b0367",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-12T12:53:43.699271Z",
     "iopub.status.busy": "2024-09-12T12:53:43.698943Z",
     "iopub.status.idle": "2024-09-12T12:53:43.707556Z",
     "shell.execute_reply": "2024-09-12T12:53:43.706687Z"
    },
    "papermill": {
     "duration": 0.014956,
     "end_time": "2024-09-12T12:53:43.709555",
     "exception": false,
     "start_time": "2024-09-12T12:53:43.694599",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 5. Model Evaluation and Analysis\n",
    "\n",
    "def load_processed_results(results_path, planet_ids):\n",
    "    all_results = {}\n",
    "    for planet_id in planet_ids:\n",
    "        all_results[planet_id] = np.load(f\"{results_path}/planet_{planet_id}_results.npz\", allow_pickle=True)\n",
    "    return all_results\n",
    "\n",
    "def prepare_data_for_modeling(all_results):\n",
    "    X = np.array([results['spectrum'] for results in all_results.values()])\n",
    "    y = np.array([results['transit_params'][:, 2] for results in all_results.values()])  # Using transit depth as target\n",
    "    return X, y\n",
    "\n",
    "def train_and_evaluate_models(X, y):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    \n",
    "    # PCA\n",
    "    pca = PCA(n_components=0.95)\n",
    "    X_train_pca = pca.fit_transform(X_train)\n",
    "    X_test_pca = pca.transform(X_test)\n",
    "    \n",
    "    # Linear Regression\n",
    "    lr = LinearRegression()\n",
    "    lr.fit(X_train_pca, y_train)\n",
    "    lr_score = lr.score(X_test_pca, y_test)\n",
    "    \n",
    "    # Random Forest\n",
    "    rf = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "    rf.fit(X_train_pca, y_train)\n",
    "    rf_score = rf.score(X_test_pca, y_test)\n",
    "    \n",
    "    print(f\"Linear Regression R2 Score: {lr_score:.4f}\")\n",
    "    print(f\"Random Forest R2 Score: {rf_score:.4f}\")\n",
    "    \n",
    "    return lr, rf, pca, X_test_pca, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2a5f388e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-12T12:53:43.717664Z",
     "iopub.status.busy": "2024-09-12T12:53:43.717392Z",
     "iopub.status.idle": "2024-09-12T12:53:43.722721Z",
     "shell.execute_reply": "2024-09-12T12:53:43.721942Z"
    },
    "papermill": {
     "duration": 0.011549,
     "end_time": "2024-09-12T12:53:43.724575",
     "exception": false,
     "start_time": "2024-09-12T12:53:43.713026",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 5.2. Final Model Selection\n",
    "\n",
    "def select_best_model(lr_model, rf_model, X_test_pca, y_test):\n",
    "    lr_mse = mean_squared_error(y_test, lr_model.predict(X_test_pca))\n",
    "    rf_mse = mean_squared_error(y_test, rf_model.predict(X_test_pca))\n",
    "    \n",
    "    print(f\"Linear Regression MSE: {lr_mse:.6f}\")\n",
    "    print(f\"Random Forest MSE: {rf_mse:.6f}\")\n",
    "    \n",
    "    if lr_mse < rf_mse:\n",
    "        print(\"Linear Regression model selected.\")\n",
    "        return lr_model\n",
    "    else:\n",
    "        print(\"Random Forest model selected.\")\n",
    "        return rf_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c92f5c88",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-12T12:53:43.732892Z",
     "iopub.status.busy": "2024-09-12T12:53:43.732621Z",
     "iopub.status.idle": "2024-09-12T12:53:43.739521Z",
     "shell.execute_reply": "2024-09-12T12:53:43.738741Z"
    },
    "papermill": {
     "duration": 0.013122,
     "end_time": "2024-09-12T12:53:43.741380",
     "exception": false,
     "start_time": "2024-09-12T12:53:43.728258",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 5.4. Uncertainty Estimation\n",
    "\n",
    "def estimate_uncertainty(model, X_pca, n_bootstrap=100):\n",
    "    predictions = []\n",
    "    for _ in range(n_bootstrap):\n",
    "        if isinstance(model, RandomForestRegressor):\n",
    "            # Randomly select estimators and average their predictions\n",
    "            n_estimators = len(model.estimators_)\n",
    "            selected_estimators = np.random.choice(model.estimators_, size=n_estimators, replace=True)\n",
    "            preds = np.mean([estimator.predict(X_pca) for estimator in selected_estimators], axis=0)\n",
    "        elif isinstance(model, LinearRegression):\n",
    "            # Add noise to the coefficients\n",
    "            coef_noise = np.random.normal(0, 0.1, size=model.coef_.shape)\n",
    "            preds = X_pca @ (model.coef_ + coef_noise).T + model.intercept_\n",
    "        else:\n",
    "            raise ValueError(\"Unsupported model type\")\n",
    "        predictions.append(preds)\n",
    "    \n",
    "    return np.std(predictions, axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6d94dd7b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-12T12:53:43.750221Z",
     "iopub.status.busy": "2024-09-12T12:53:43.749614Z",
     "iopub.status.idle": "2024-09-12T12:53:43.756863Z",
     "shell.execute_reply": "2024-09-12T12:53:43.756048Z"
    },
    "papermill": {
     "duration": 0.01383,
     "end_time": "2024-09-12T12:53:43.758820",
     "exception": false,
     "start_time": "2024-09-12T12:53:43.744990",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 5.6. Submission Preparation\n",
    "\n",
    "def prepare_submission(model, pca_model, all_results, output_file):\n",
    "    planet_ids = list(all_results.keys())\n",
    "    spectra = []\n",
    "    uncertainties = []\n",
    "    \n",
    "    for planet_id in planet_ids:\n",
    "        spectrum = all_results[planet_id]['spectrum']\n",
    "        spectrum_pca = pca_model.transform(spectrum.reshape(1, -1))\n",
    "        predicted_spectrum = model.predict(spectrum_pca).flatten()\n",
    "        spectrum_uncertainty = estimate_uncertainty(model, spectrum_pca)\n",
    "        \n",
    "        # Ensure the predicted spectrum and uncertainty have the correct shape\n",
    "        if predicted_spectrum.ndim == 2:\n",
    "            predicted_spectrum = predicted_spectrum[0]\n",
    "        if spectrum_uncertainty.ndim == 2:\n",
    "            spectrum_uncertainty = spectrum_uncertainty[0]\n",
    "        \n",
    "        spectra.append(predicted_spectrum)\n",
    "        uncertainties.append(spectrum_uncertainty)\n",
    "    \n",
    "    submission_df = pd.DataFrame({\n",
    "        'planet_id': planet_ids,\n",
    "        'spectrum': spectra,\n",
    "        'uncertainty': uncertainties\n",
    "    })\n",
    "    \n",
    "    submission_df.to_csv(output_file, index=False)\n",
    "    print(f\"Submission file saved to {output_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "abf52f92",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-12T12:53:43.767127Z",
     "iopub.status.busy": "2024-09-12T12:53:43.766826Z",
     "iopub.status.idle": "2024-09-12T12:53:43.775313Z",
     "shell.execute_reply": "2024-09-12T12:53:43.774480Z"
    },
    "papermill": {
     "duration": 0.014749,
     "end_time": "2024-09-12T12:53:43.777240",
     "exception": false,
     "start_time": "2024-09-12T12:53:43.762491",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 5.8. Model Interpretation and Visualization\n",
    "\n",
    "def visualize_important_features(model, pca_model, wavelengths):\n",
    "    if isinstance(model, RandomForestRegressor):\n",
    "        importance = model.feature_importances_\n",
    "    elif isinstance(model, LinearRegression):\n",
    "        importance = np.abs(model.coef_[0])\n",
    "    \n",
    "    # Transform importance back to original feature space\n",
    "    original_importance = pca_model.inverse_transform(importance)\n",
    "    \n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.plot(wavelengths, original_importance)\n",
    "    plt.title('Feature Importance Across Wavelengths')\n",
    "    plt.xlabel('Wavelength')\n",
    "    plt.ylabel('Importance')\n",
    "    plt.show()\n",
    "\n",
    "def plot_example_prediction(model, pca_model, all_results, planet_id):\n",
    "    spectrum = all_results[planet_id]['spectrum']\n",
    "    actual_params = all_results[planet_id]['transit_params']\n",
    "    \n",
    "    spectrum_pca = pca_model.transform(spectrum.reshape(1, -1))\n",
    "    predicted_params = model.predict(spectrum_pca).flatten()\n",
    "    \n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.plot(spectrum, label='Actual Spectrum')\n",
    "    plt.plot(predicted_params, label='Predicted Transit Depth')\n",
    "    plt.title(f'Spectrum and Predicted Transit Depth for Planet {planet_id}')\n",
    "    plt.xlabel('Wavelength Index')\n",
    "    plt.ylabel('Value')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d201076d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-12T12:53:43.785901Z",
     "iopub.status.busy": "2024-09-12T12:53:43.785623Z",
     "iopub.status.idle": "2024-09-12T12:53:44.001572Z",
     "shell.execute_reply": "2024-09-12T12:53:44.000562Z"
    },
    "papermill": {
     "duration": 0.222536,
     "end_time": "2024-09-12T12:53:44.003743",
     "exception": false,
     "start_time": "2024-09-12T12:53:43.781207",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    try:\n",
    "        data_path = \"/kaggle/input/ariel-data-challenge-2024\"\n",
    "        train_adc_info = pd.read_csv(f\"{data_path}/train_adc_info.csv\", index_col='planet_id')\n",
    "        axis_info = pd.read_parquet(f\"{data_path}/axis_info.parquet\")\n",
    "        \n",
    "        logging.info(\"Starting planet processing\")\n",
    "        all_results = process_all_planets(data_path, train_adc_info, axis_info)\n",
    "        \n",
    "        logging.info(\"Preparing data for modeling\")\n",
    "        X, y = prepare_data_for_modeling(all_results)\n",
    "\n",
    "        logging.info(\"Training and evaluating models\")\n",
    "        lr_model, rf_model, pca_model, X_test_pca, y_test = train_and_evaluate_models(X, y)\n",
    "        \n",
    "        logging.info(\"Selecting best model\")\n",
    "        best_model = select_best_model(lr_model, rf_model, X_test_pca, y_test)\n",
    "        \n",
    "        logging.info(\"Preparing submission\")\n",
    "        prepare_submission(best_model, pca_model, all_results, \"submission.csv\")\n",
    "\n",
    "        logging.info(\"Visualizing results\")\n",
    "        wavelengths = list(all_results.values())[0]['wavelengths']\n",
    "        visualize_important_features(best_model, pca_model, wavelengths)\n",
    "        \n",
    "        example_planet_id = list(all_results.keys())[0]\n",
    "        plot_example_prediction(best_model, pca_model, all_results, example_planet_id)\n",
    "        \n",
    "        logging.info(\"Analysis completed successfully\")\n",
    "    except Exception as e:\n",
    "        logging.error(f\"An error occurred: {str(e)}\", exc_info=True)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "databundleVersionId": 9188054,
     "sourceId": 70367,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 30761,
   "isGpuEnabled": true,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 5.567474,
   "end_time": "2024-09-12T12:53:44.425703",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-09-12T12:53:38.858229",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
